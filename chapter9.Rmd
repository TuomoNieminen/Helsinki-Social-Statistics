---
title       : Hypothesis testing
description : We all might be statistically different, but maybe we are part of the 68%.

--- type:MultipleChoiceExercise lang:r xp:100 skills:1 key:ee77c10ab2

## Statistical hypothesis testing

In [statistical hypothesis testing](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) we want to test if a model or an assumption is supported by the data. To do a statistical test, you need to follow these steps:

- Set the [null hypothesis](https://en.wikipedia.org/wiki/Null_hypothesis) and the [alternative hypothesis](https://en.wikipedia.org/wiki/Alternative_hypothesis).
- Decide the level of [significance](https://en.wikipedia.org/wiki/Statistical_significance) (usually marked as $\alpha$)
- Calculate the [test statistics](https://en.wikipedia.org/wiki/Test_statistic)
- Compute the[ p-value](https://en.wikipedia.org/wiki/P-value)
- Interpret the results of the test


Which of the following statements is true?

*** =instructions
- A p-value measures the probability that the studied hypothesis is true
- A statistically significant result means that the result also has practical significance
- Even if an experiment is poorly designed, a statistically significant result means the results can be published
- P-values can indicate how incompatible the data are with a specified statistical model


*** =hint
- I you're uncertain, just try a plausible option and submit the answer: you will get feedback on your answer




*** =pre_exercise_code
```{r}

```


*** =sct
```{r}
# submission correctness tests

msg1 <- "This is a common misinterpretation. A p-value is a statement about data in relation to a specified hypothetical explanation, and is not a statement about the explanation itself."
msg2 <- "This is a common misinterpretation. Any effect, no matter how tiny, can produce a significant p-value if the sample size or measurement precision is high enough. Also large effects may produce unsignificant p-values if the sample size is small or measurements are imprecise."
msg3 <- "A significant p-value has absolutely no value if the experiment it poorly designed and/or reported. Whenever a researcher chooses what to present based on statistical results, valid interpretation of those results is severely compromised if the reader is not informed of the choice and its basis."
msg4 <- "Correct! A p-value provides one approach to summarizing the incompatibility between a particular set of data and a proposed model or hypothesis relating that data."

test_mc(correct = 4, feedback_msgs = c(msg1, msg2, msg3, msg4))

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```

--- type:NormalExercise lang:r xp:100 skills:1  key:ce010c22a3

## Test statistics

After setting the hypotheses, we can use the data we have and calculate a test statistic, which is a statistical summary of the data. What kind of test statistic to use, depends on the situation. 

A $z$ test statistic is computed by standardizing a normal random variable (here $\bar{x}$). 

$$z = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}$$

where $\mu_0$ is the hypothesized expected value of $\bar{x}$, $s$ is the sample standard deviation and $n$ is the sample size. A $z$ test has limited practical use but it demonstrates the idea of a test statistic well enough. The widely used *t-test* is very similar.

Notice how the denominator has the standard error of $\bar{x}$. 


*** =instructions
- Create objects `stra` and `n`
- Set a null hypothesis that the expected value of strategic learning is 3 and create object `mu0`
- Compute the sample mean and the standard error
- Compute the test statistic $z$. If `mu0` is the actual expected value, the random variable $Z$ corrspoinding the value $z$ follows the standard normal distribution: $Z \sim N(0,1)$
- Print out the value of the test statistic
- Visualize the distribution. According to the picture and assuming that $Z \sim N(0,1)$, what is the probability that the test statistic $Z$ would take on a value even further away from it's expected value than the current value $z$? Save this probability to the object `p`.

*** =hint
- Look at the visualization. How much probability in total is at the "tails"" of the distribution?
- Remember that probability is measured between 0 and 1
- |Z| is the absolute value of Z, meaning that $P(|Z| > z) = P(Z < -z) + P(Z > z)$

*** =pre_exercise_code
```{r}
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

zplot <- function(critical) {
  critical <- round(critical, 2)
  z <- c(-critical, critical)
  par(mar = c(7,4,5,4))
  x <- (-40:40)/10
  y <- dnorm(x)
  main = paste("The N(0, 1) distribution \n z = ",critical)
  plot(x, y, type = "l", xaxt = "n", ylab = "n", main = main)
  axis(1, at = c(-3,  0,  3))
  axis(1, at = round(z, 2) , col.ticks = "red", las = 2)
  
  # highlight critical regions, add matching percentages
  x1 <- x[x<=min(z)]; x2 <- x[x>=max(z)]
  a <- round(pnorm(min(z)),2)
  
polygon(c(min(x1),x1, max(x1), min(x2), x2, max(x2)),
            c(0, dnorm(x1),0, 0, dnorm(x2), 0), col = "grey60")
      text(x = c(-3.5, 3.5), y = c(0.08,0.08), labels = paste0(a*100,"%"), cex = 1.5)
      text(x = 0, y = 0.08, labels=paste0(100*(1-a*2),"%"), cex = 1.5)
}


```


*** =sample_code
```{r}
# learning2014 is available

# Strategic learning scores and number of observations
stra <- learning2014$stra
n <- length(stra)

# H0: mu = 3
mu0 <- 3

# Sample mean of strategic learning
x_bar <- 

# Standard error of the sample mean
error <-

# The test statistic
z <- (x_bar - mu0) / error

# Print out the value of the test statistic


# Visualize the N(0, 1) distribution and the value of z 
zplot(z)

# P(|Z| > z)
p <- 

```

*** =solution
```{r}
# learning2014 is available

# Strategic learning scores and number of observations
stra <- learning2014$stra
n <- length(stra)

# H0: mu = 3
mu0 <- 3

# Sample mean of strategic learning
x_bar <- mean(stra)

# Standard error of the sample mean
error <- sd(stra) / sqrt(n)

# The test statistic
z <- (x_bar - mu0) / error

# Print out the value of the test statistic
z

# Visualize the N(0, 1) distribution and the value of z 
zplot(z)

# P(|Z| > z)
p <- 0.14



```

*** =sct
```{r}
# submission correctness tests

test_object("x_bar")
test_object("error")
test_output_contains("z", incorrect_msg = "Please print out the value of the test statistic")
test_object("p", incorrect_msg ="Please create object p with the correct probability value")

test_error()

# Final message the student will see upon completing the exercise
success_msg("Great work!")

```

--- type:NormalExercise lang:r xp:100 skills:1  key:c5ba44e024

## Peculiar p-values

As you just saw, it is possible to calculate probabilities related to the test statistic if we assume that the null hypothesis is true. The **p-value** is defined as the probability of obtaining a result equal to or "more extreme" than what was actually observed, when the null hypothesis is true.

What exactly is considered "more extreme" depends on the alternative hypothesis. For example, if the two hypothesis concerning the parameter $\mu$ are

- $H_0 : \mu = 3$
- $H_1 : \mu < 3$

Then cases where the estimate of $\mu$ is higher than 3 are never critical to the null hypothesis no matter how far away from 3 they are.

*** =instructions
- Create objects `stra` and `n`
- Compute the mean of strategic learning
- Set the alternative hypothesis $H_0: \mu = 3$ and compute the z test statistic
- Print out the value of the test statistic
- Set the alternative hypothesis $H_1: \mu > 3$. Based on the plot, create object `p1` storing the p-value $P(Z > z)$. 
- Set the alternative hypothesis $H_1: \mu \neq 3$. Based on the plot, create object `p2` storing the p-value $P(|Z| > z)$. 

*** =hint
- Interpret the `p1` and `p2` from the plot.
- Rememeber that probability is a measure between 0 and 1
- |Z| is the absolute value of Z, meaning that $P(|Z| > z) = P(Z < -z) + P(Z > z)$


*** =pre_exercise_code
```{r}
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

zplot <- function(critical) {
  critical <- round(critical, 2)
  z <- c(-critical, critical)
  par(mar = c(7,4,5,4))
  x <- (-40:40)/10
  y <- dnorm(x)
  main = paste("The N(0, 1) distribution \n z = ",critical)
  plot(x, y, type = "l", xaxt = "n", ylab = "", main = main, xlab="z")
  axis(1, at = c(-3,  0,  3))
  axis(1, at = round(z, 2) , col.ticks = "red", las = 2)
  
  # highlight critical regions, add matching percentages
  x1 <- x[x<=min(z)]; x2 <- x[x>=max(z)]
  a <- round(pnorm(min(z)),2)
  
polygon(c(min(x1),x1, max(x1), min(x2), x2, max(x2)),
            c(0, dnorm(x1),0, 0, dnorm(x2), 0), col = "grey60")
      text(x = c(-3.5, 3.5), y = c(0.08,0.08), labels = paste0(a*100,"%"), cex = 1.5)
      text(x = 0, y = 0.08, labels=paste0(100*(1-a*2),"%"), cex = 1.5)
}

stra <- learning2014$stra
n <- length(stra)

# Set H0: mu = 3
z <- (mean(stra) - 3) / (sd(stra) / sqrt(n))
# Visualize the N(0, 1) distribution and the value of z 
zplot(z)


```

*** =sample_code
```{r}
# learning2014 is available

# Strategic learning scores and number of observations
stra <- learning2014$stra
n <- length(stra)

# Set H0: mu = 3

# Sample mean
mean(stra)

# Test statistic
z <- (mean(stra) - 3) / (sd(stra) / sqrt(n))


# Set H1: mu > 3
# -> p-value = P(Z > z)
p1 <- 
  
# Set H1: mu != 3
# -> p-value = P(|Z| > z)
p2 <- 
  

```

*** =solution
```{r}
# learning2014 is available

# Strategic learning scores and number of observations
stra <- learning2014$stra
n <- length(stra)

# Set H0: mu = 3

# Sample mean
mean(stra)

# Test statistic
z <- (mean(stra) - 3) / (sd(stra) / sqrt(n))
z

# Set H1: mu > 3
# -> p-value = P(Z > z)
p1 <- 0.07
  
# Set H1: mu != 3
# -> p-value = P(|Z| > z)
p2 <- 0.14


```

*** =sct
```{r}
# submission correctness tests
test_object("p1")
test_object("p2")

# test if the students code produces an error
test_error()
success_msg("Excellent work!")

```

--- type:MultipleChoiceExercise lang:r xp:100 skills:1  key:a4b47ea868

## Alternative hypothesis: which way to go?!

The null hypothesis usually corresponds to the commonly or previously assumed state. The goal of hypothesis testing is usually to show that data does not support the null hypothesis.  

The alternative hypothesis on the other hand is about change or the new assumption. Some possible alternative hypothesis could be: Are students getting fewer exam points than previous years? Are people buing more groceries from store nowadays than in the '90s? Have the voting rates changed? 

The alternative hypothesis can be one-sided or two-sided:

- **one-sided**: previous mean $<$ new mean
- **one-sided**: previous mean $>$ new mean
- **two-sided**: previous mean $\ne$ new mean

In cases above the null hypothesis would be *H0*: previous mean $=$ new mean.

Alternative hypothesis also determine the rejection region of the test. Beside are three plots that visualize the rejection regions (with the significance level $\alpha$ = 0.05). Look at the plots and choose the correct claim below.

*** =instructions
- Plot 3 has on-sided alternative hypothesis. 
- The alternative hypothesis "*H1*: previous mean $>$ new mean" belongs to plot 1.
- The alternative hypothesis "*H1*: previous mean $\ne$ new mean" belongs to plot 3.
- Plot 1 has two-sided alternative hypothesis.
- The alternative hypothesis "*H1*: previous mean $<$ new mean" belongs to plot 2.

*** =hint
- hint 1
- hint 2


*** =pre_exercise_code
```{r}
learning2014 <-  read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

regions <- function(a, direction) {
  par(col = "grey60", cex=1.2)
  x <- (-50:50) / 10
  y <- dnorm(x)
  col1 <- "steelblue"
  lwe <- 2
  plot(x, y,type = "l", main = "", xlab = "", yaxt = "n", ylab = "",lwd = lwe, axes=F)
  ab<-abline(h=0, lwd=lwe)
  if (direction == 'l') {
    q1 <- qnorm(a)
    x1 <- x[x <= q1]
    polygon(c(min(x1), x1, max(x1)),c(0, dnorm(x1), 0),col = col1,border = col1,lwd = lwe)
    ab
    title("Plot 1", adj=0)
    text(-2.5, .1, paste(a*100, "%"), col="steelblue", cex=1.5)
    }
  if (direction == 'r') {
    q1 <- qnorm(1 - a)
    x1 <- x[x >= q1]
    polygon(c(min(x1), x1, max(x1)),c(0, dnorm(x1), 0),col = col1,border = col1,lwd = lwe)
    ab
    title("Plot 2", adj=0)
    text(2.5, .1, paste(a*100, "%"), col="steelblue", cex=1.5)
    }
  if (direction == 'm') {
    q1 <- qnorm(a / 2)
    q2 <- qnorm(1 - (a / 2))
    x1 <- x[x <= q1]
    x2 <- x[x >= q2]
    polygon(c(min(x1), x1, max(x1)),c(0, dnorm(x1), 0), col = col1, border = col1, lwd = lwe)
    polygon(c(min(x2), x2, max(x2)),c(0, dnorm(x2), 0), col = col1, border = col1, lwd = lwe)
    ab
    title("Plot 3", adj=0)
    text(c(-2.5,2.5), c(.1,.1), paste((a/2)*100, "%"), col="steelblue", cex=1.5)
  }
}

par(mfrow=c(3,1), mar=c(1,3,2,3))
a1<-.05
regions(a=a1, direction = 'l')
regions(a=a1, direction = 'r')
regions(a=a1, direction = 'm')

```

*** =sct
```{r}

msg1 = "The rejection region indicates that the test is two-sided."
msg2 = "Sorry, wrong direction!"
msg3 = "Yes, correct! You can reject values that differ too much from the previous mean."
msg4 = "The rejection region indicates that the test is one-sided."
msg5 = "Sorry, wrong direction!"

test_mc(correct = 3, feedback_msgs = c(msg1,msg2,msg3,msg4, msg5))
success_msg("Nicely done!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:9b63d0cb6a

## Meet the tests! (1)

T-test is very common statistical test. It can be used for example to test if the means of two groups differ from each other statistically. You can also test if the mean of some variable is statistically different from predetermined value. 

The t-test is done in R with the `t.test()` function. The same function does one or two sided tests or a paired t-test. You can check the help page (use `?t.test`) of the function to see the arguments and options. By default, the alternative hypothesis is "two.sided".

*** =instructions
- Create subsets of the `learning2014` dataset: separate the dataset by gender. Save new subsets to `women` and `men` objects. Variable `gender` is a factor with two levels: 'N' and 'M'.
- In the data there was variable `deep` which descripted the deep learning scores of the students. Maybe deep learning is different with women and men? Let's test that. 
- But first it is important to look at the descriptive statistics. Do you remember a handy function called `summary()`? Look what the summaries say about variable `deep` on both sexes.
- The `t.test()` function prints you the results of the test on the console. In the print you can see numbers the test produced: test statistics (*t*-value), degrees of freedom (df) and the p-value. It also calculates the 95% confidence interval and sample estimates.
- So there was no such difference in deep learning scores between genders (why we can make that conclusion?) but how about the strategic learning (variable `stra`) between genders? 
- Look at the summaries of `stra` for women and men and to the t-test. Interpret the results from the test print.

*** =hint
- To get the men's subset, you need to specify the gender to be 'M'. You need to have to equation marks (see chapter 6: Logical comparison).
- `women` and `men` are data frames, and you can get the variables from data frame with $-mark. 
- You can see the first six rows of data frame with the function `head()`.
- Remember that dot is the decimal mark in R, not comma.


*** =pre_exercise_code
```{r}
learning2014 <-  read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)
```

*** =sample_code
```{r}
# Separate dataset by gender
women <- subset(learning2014, gender == 'N')
men <-

# Summaries of deep learning for men and women
summary(women$deep)


# T-test of deep learning for men and women
t.test(women$deep, men$deep)

# Summaries of stategic learning for men and women



# T-test of stategic learning for men and women


```

*** =solution
```{r}
# Separate dataset by gender
women <- subset(learning2014, gender == 'N')
men <- subset(learning2014, gender == 'M')

# Summaries of deep learning for men and women
summary(women$deep)
summary(men$deep)

# T-test of deep learning for men and women
t.test(women$deep, men$deep)

# Summaries of stategic learning for men and women
summary(women$stra)
summary(men$stra)

# T-test of stategic learning for men and women
t.test(women$stra, men$stra)

```

*** =sct
```{r}
# submission correctness tests

# example tests:
test_output_contains("summary(men$stra)", "Did you use `summary()` on the mens stategic learning scores?")
test_output_contains("summary(women$stra)", "Did you use `summary()` on the womens stategic learning scores?")
test_output_contains("t.test(women$stra, men$stra)", "Did you do the t-test of stategic learning for men and women?")

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:c033eeaa78

## Meet the tests! (2)

There are many statistical tests for different purposes. So, there are many test functions in R. In the next exercises we will get familiar with couple of them.

The [chi-square](https://en.wikipedia.org/wiki/Chi-squared_test) test (also written as $\chi^2$-test) is well known statistical test. It can be used to test whether two variables are *independent* from each other (e.g. one variable is not affected by the presence of another). The test can also be used as goodness-of-fit test: with it we can check if the observed frequency distribution differs from a theoretical distribution.

In R you can do the chi-squared test with the function `chisq.test()`. Start testing by looking at the example code!

*** =instructions
- Create object `grades` from the variable `points` from the learning2014 dataset with the `cut()` function. Set the break points with vector `c(0, 15, 19, 23, 27, 33)`. Use also the argument `include.lowest = TRUE` to take zero values into count.
- Create a table of `gender` and `grades` and save it as `gender_grades_tbl`. Print the table.
- Test the null hypothesis that grades are independent from gender. What could be the alternative hypothesis in this case? Let's use the 0.05 significance level.
- Use the function `chisq.test()` to do the chi-squared test of independence. Give the table you created as an argument to the function.
- See the print that the test function produces. What conclusions can you make?

*** =hint
- You get variables from dataset with the $-mark, for example `learning2014$gender`.
- the `cut()` function has an argument that tells where to break the values. Type `?cut` to console to see the help page of the function (or use google).
- You can create a table with `table()`. Help page will help you if you do not remember how to use it. 
- `chisq.test(gender_grades_tbl)` is the code needed to do the testing. 


*** =pre_exercise_code
```{r}
# pre exercise code here
learning2014 <-  read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)
```

*** =sample_code
```{r}
# learning2014 is available

# Create grades from 'points' 


# Table of gender and grades



# Chi-squared test of independence
chisq.test(gender_grades_tbl)

```

*** =solution
```{r}
# learning2014 is available

# Create grades from 'points' 
grades <- cut(learning2014$points, breaks = c(0, 15, 19, 23, 27, 33), include.lowest = TRUE)

# Table of gender and grades
gender_grades_tbl<-table(learning2014$gender, grades)
gender_grades_tbl

# Chi-squared test of independence
chisq.test(gender_grades_tbl)


```

*** =sct
```{r}
# submission correctness tests
test_object("grades", incorrect_msg = "Did you create `grades`?")
test_object("gender_grades_tbl", incorrect_msg = "Did you create `gender_grades_tbl`?")
test_function("chisq.test", args=c("x"), incorrect_msg = "Did you do the chi-squared test?")

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:925dc7c1a6

## Packages in R

There are a lot of functions in R. But actually, the functions in R come from a standard set of packages. Besides the basic packages, you can install and use (or develop!) other packages too. 

You can install packages through CRAN. What is CRAN? The answer can be found from their website [https://cran.r-project.org/](https://cran.r-project.org/): 
> CRAN is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R. 

List of available CRAN packages can be seen [here](https://cran.r-project.org/web/packages/available_packages_by_name.html). Because the packages are made by different R users, the codes may have some style differences. In those cases, one needs to rely in the documentation of the code.

If you have R in your own computer, you can install packages with code `install.packages(*name_of_the_package*)`. But because we are working in DataCamp, the packages are already installed for you. So we don't need to worry about installation for now.

To use the installed packages, you need to access them. This is done by calling `library(*name_of_the_package*)`.

*** =instructions
- One of the most famous and used packages outside the basic R is `ggplot2`. The `ggplot2` packages is a plotting system for R, and it draws pretty pictures for you with small effort. 
- The `ggplot2` package has a website [http://ggplot2.org/](http://ggplot2.org/) where you can see documentation about the package. 
- Execute the access code for `ggplot2`.
- Draw a plot of gender and points. The `fill` argument adds a legend to the plot. 
- Create the `grades` object.
- Do a plot of `grades` and `attitude`. Set `grades` as a legend.

*** =hint
- Copy the code of the `qplot()` function. and change `gender` to `grades` and `points` to `attitude`. Remember to change the `fill` argument also.


*** =pre_exercise_code
```{r}
learning2014 <-  read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)
```

*** =sample_code
```{r}
# learning2014 is available 

# Access ggplot2
library("ggplot2")

# Draw a plot of gender and points
qplot(gender, points, data=learning2014, geom="boxplot", fill=gender)

# Create the grades factor
grades <- cut(learning2014$points, breaks = c(0, 11, 15, 19, 23, 27, 33), include.lowest = TRUE)

# Draw a plot of grades and attitude


```

*** =solution
```{r}
#learning2014 is available 

# Access ggplot2
library("ggplot2")

# Draw a plot of gender and points
qplot(gender, points, data=learning2014, geom="boxplot", fill=gender)

# Create the grades factor
grades <- cut(learning2014$points, breaks = c(0, 11, 15, 19, 23, 27, 33), include.lowest = TRUE)

# Draw a plot of grades and attitude
qplot(grades, attitude, data=learning2014, geom="boxplot", fill=grades)

```

*** =sct
```{r}
# test_function("qplot", args=c("x", "y", "fill"), incorrect_msg = "Did you draw a plot of `grades` and `attitude`?")

test_error()

# Final message the student will see upon completing the exercise
success_msg("You have the keys do anything. Awesome!")

```
