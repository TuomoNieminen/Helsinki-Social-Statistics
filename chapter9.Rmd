---
title       : Hypothesis testing
description : We all might be statistically different, but maybe we are part of the 68%.

--- type:MultipleChoiceExercise lang:r xp:100 skills:1 key:ee77c10ab2

## Statistical hypothesis testing

In [statistical hypothesis testing](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) we want to test if our claim or something we assume is supported by the data. So we set our [*null hypothesis*](https://en.wikipedia.org/wiki/Null_hypothesis) and our [*alternative hypothesis*](https://en.wikipedia.org/wiki/Alternative_hypothesis), and see what the numbers tell us about them.  

After setting the hypotheses, we can look at the data and calculate the test statistic. What test statistic to use, depends on the test you are doing. With the test statistics, you can calculate the (famous) p-value. The p-value tells you something about the hypotheses and it can be used as a guide line. The p-value and other knowledge of the field you are testing, you can reject or not reject the null hypothesis. 

*** =instructions
- instruction 1
- instruction 2

*** =hint
- hint 1
- hint 2


*** =pre_exercise_code
```{r}

```

*** =sct
```{r}
# submission correctness tests

# example tests:
# test_output_contains("output")
# test_object("object_name")
# test_function("function_name", args=c("arg1"))

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```
--- type:MultipleChoiceExercise lang:r xp:100 skills:1 key:8dfc56d628

## (Null hypothesis:) which way to go?!

The null hypothesis is usually the commonly or previously known. The alternative hypothesis on the other hand is about change or the new assumption. Some possible alternative hypothesis could be: Are students getting fewer exam points than previous years? Are people buing more groceries from store nowadays than in the '90s? Have the voting rates changed? Or the alternative hypothesis could be (with bit more mathematically written):

- previous mean <code>&#8804;</code> new mean (one-sided)
- previous mean <code>&#8805;</code> new mean (one-sided)
- previous mean <code>&#8800;</code> new mean (two-sided)

Alternative hypothesis also determine the rejection region of the test. 

*** =instructions
- instruction 1
- instruction 2

*** =hint
- hint 1
- hint 2


*** =pre_exercise_code
```{r}
learning2014 <-  read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

regions <- function(a, direction) {
  par(col = "grey60")
  x <- (-50:50) / 10
  y <- dnorm(x)
  col1 <- "steelblue"
  lwe <- 2
  plot(x, y,type = "l", main = "", xlab = "", yaxt = "n", ylab = "",lwd = lwe, axes=F)
  ab<-abline(h=0, lwd=lwe)
  if (direction == 'l') {
    q1 <- qnorm(a)
    x1 <- x[x <= q1]
    polygon(c(min(x1), x1, max(x1)),c(0, dnorm(x1), 0),col = col1,border = col1,lwd = lwe)
    ab
    title("Plot 1", adj=0)}
  if (direction == 'r') {
    q1 <- qnorm(1 - a)
    x1 <- x[x >= q1]
    polygon(c(min(x1), x1, max(x1)),c(0, dnorm(x1), 0),col = col1,border = col1,lwd = lwe)
    ab
    title("Plot 2", adj=0)
  }
  if (direction == 'm') {
    q1 <- qnorm(a / 2)
    q2 <- qnorm(1 - (a / 2))
    x1 <- x[x <= q1]
    x2 <- x[x >= q2]
    polygon(c(min(x1), x1, max(x1)),c(0, dnorm(x1), 0), col = col1, border = col1, lwd = lwe)
    polygon(c(min(x2), x2, max(x2)),c(0, dnorm(x2), 0), col = col1, border = col1, lwd = lwe)
    ab
    title("Plot 3", adj=0)
  }
}

par(mfrow=c(3,1), mar=c(1,1,2,1))
a1<-.05
regions(a=a1, direction = 'l')
regions(a=a1, direction = 'r')
regions(a=a1, direction = 'm')
```
*** =sct
```{r}
# submission correctness tests

# example tests:
# test_output_contains("output")
# test_object("object_name")
# test_function("function_name", args=c("arg1"))

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:c033eeaa78

## Meet the tests! (1)

There are many statistical tests for different purposes. So, there are many test functions in R. In the next exercises we will get familiar with couple of them.

The [chi-square](https://en.wikipedia.org/wiki/Chi-squared_test) test (also written as $\chi^2$-test) is well known statistical test. It can be used to test whether two variables are *independent* from each other (e.g. one variable is not affected by the presence of another). The test can also be used as goodness-of-fit test: with it we can check if the observed frequency distribution differs from a theoretical distribution.

In R you can do the chi-squared test with the function `chisq.test()`. Start testing by looking at the example code!

*** =instructions
- Create object `grades` from the variable `points` from the learning2014 dataset with the `cut()` function. Set the break points with vector `c(0, 11, 15, 19, 23, 27, 33)`. 
- Create a table of `gender` and `grades`. Save the table as `gender_grades_tbl`.
- Test the null hypothesis that grades are independent from gender. What could be the alternative hypothesis in this case? Let's use the 0.05 significance level.
- Use the function `chisq.test()` to do the chi-squared test of independence. Give the table you created as an argument to the function.
- See the print that the test function produces. What conclusions can you make?

*** =hint
- You get variables from dataset with the $-mark, for example `learning2014$gender`.
- the `cut()` function has an argument that tells where to break the values. Type `?cut` to console to see the help page of the function (or use google).
- You can create a table with `table()`. Help page will help you if you do not remember how to use it. 
- `chisq.test(gender_grades_tbl)` is the code needed to do the testing. 


*** =pre_exercise_code
```{r}
# pre exercise code here
learning2014 <-  read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)
```

*** =sample_code
```{r}
# learning2014 is available

# Create grades from 'points' 


# Table of gender and grades


# Chi-squared test of independence
chisq.test(gender_grades_tbl)

```

*** =solution
```{r}
# learning2014 is available

# Create grades from 'points' 
grades <- cut(learning2014$points, breaks = c(0, 11, 15, 19, 23, 27, 33))

# Table of gender and grades
gender_grades_tbl<-table(learning2014$gender, grades)

# Chi-squared test of independence
chisq.test(gender_grades_tbl)


```

*** =sct
```{r}
# submission correctness tests
test_object("grades", incorrect_msg = "Did you create `grades`?")
test_object("gender_grades_tbl", incorrect_msg = "Did you create `gender_grades_tbl`?")
test_function("chisq.test", args=c("x"), incorrect_msg = "Did you do the chi-squared test?")

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:9b63d0cb6a

## Meet the tests! (2)

T-test is very common statistical test. It can be used for example to test if the means of two groups differ from each other statistically. You can also test if the mean of some variable is statistically different from predetermined value. 

The t-test in done in R with the `t.test()` function. The same function does one or two sided tests or a paired t-test. You can check the help page (use `?t.test`) of the function to see the arguments and options. By default, the alternative hypothesis is "two.sided".

*** =instructions
- Create subsets of the `learning2014` dataset: separate the dataset by gender. Save new subsets to `women` and `men` objects. Variable `gender` is a factor with two levels: 'N' and 'M'.
- In the data there was variable `deep` which descripted the deep learning scores of the students. Maybe deep learning is different with women and men? Let's test that. 
- But first it is important to look at the descriptive statistics. Do you remember a handy function called `summary()`? Look what the summaries say about variable `deep` on both sexes.
- The `t.test()` function prints you the results of the test on the console. In the print you can see numbers the test produced: test statistics (*t*-value), degrees of freedom (df) and the p-value. It also calculates the 95% confidence interval and sample estimates.
- So there was no such difference in deep learning scores between genders (why we can make that conclusion?) but how about the strategic learning (variable `stra`) between genders? 
- Look at the summaries of `stra` for women and men and to the t-test. See the print of the test
- Save the p-value to the object `p`. Use all the decimals the print shows you.

*** =hint
- To get the men's subset, you need to specify the gender to be 'M'. You need to have to equation marks (see chapter 6: Logical comparison).
- `women` and `men` are data frames, and you can get the variables from data frame with $-mark. 
- You can see the first six rows of data frame with the function `head()`.
- Remember that dot is the decimal mark in R, not comma.
- The p-value has 5 decimals (0.xxxxx) and you need to write all of them to pass the exercise. 


*** =pre_exercise_code
```{r}
learning2014 <-  read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)
```

*** =sample_code
```{r}
# Separate dataset by gender
women <- subset(learning2014, gender == 'N')
men <-

# Summaries of 'deep'
summary(women$deep)


# T-test of 'deep'
t.test(women$deep, men$deep)

# Summaries of 'stra'



# T-test of 'stra'


# P-value
p <- 

```

*** =solution
```{r}
# Separate dataset by gender
women <- subset(learning2014, gender == 'N')
men <- subset(learning2014, gender == 'M')

# Summaries of 'deep'
summary(women$deep)
summary(men$deep)

# T-test of 'deep'
t.test(women$deep, men$deep)

# Summaries of 'stra'
summary(women$stra)
summary(men$stra)

# T-test of 'stra'
t.test(women$stra, men$stra)

# P-value
p <- 0.04945

```

*** =sct
```{r}
# submission correctness tests

# example tests:
# test_output_contains("output")
# test_object("object_name")
# test_function("function_name", args=c("arg1"))

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:0b42a1089b

## Peculiar p-values

Under construction.

*** =instructions
- instruction 1
- instruction 2

*** =hint
- hint 1
- hint 2


*** =pre_exercise_code
```{r}
# pre exercise code here
```

*** =sample_code
```{r}
# sample code here
```

*** =solution
```{r}
#solution code here
```

*** =sct
```{r}
# submission correctness tests

# example tests:
# test_output_contains("output")
# test_object("object_name")
# test_function("function_name", args=c("arg1"))

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```
--- type:NormalExercise lang:r xp:100 skills:1 key:925dc7c1a6

## Packages in R

Under construction.

*** =instructions
- instruction 1
- instruction 2

*** =hint
- hint 1
- hint 2


*** =pre_exercise_code
```{r}
# pre exercise code here
```

*** =sample_code
```{r}
# sample code here
```

*** =solution
```{r}
#solution code here
```

*** =sct
```{r}
# submission correctness tests

# example tests:
# test_output_contains("output")
# test_object("object_name")
# test_function("function_name", args=c("arg1"))

# test if the students code produces an error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Good work!")

```

