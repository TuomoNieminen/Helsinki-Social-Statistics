---
title       : Regression
description : UNDER CONSTRUCTION

--- type:NormalExercise lang:r xp:150 skills:1 key:e2d130649d

## Exploring the relationship of two variables

It is always a good idea to start with the simplest possible explorations before more complicated statistical analysis. A scatter plot is always a good starting point when analyzing the relationship between variables. Sample correlations are another useful tool.

In the ggplot2 library, scatter plots can be drawn with the general `qplot()` function. `geom_smooth()` can be used to add a regression line to the plot. In base R `cor.test()` can be used to compute a correlation with a confidence interval.

*** =instructions
- Access the ggplot2 library, modify the learning2014 data and draw a scatter plot of `attitude` and `points`.
- Adjust the scatter plot: Add code `+ geom_smooth()` after `qplot()`. Write the code to the same line and do not forget the plus sign. Execute the row.
- Give the function `geom_smooth()` the argument `method = "lm"` and execute the line again. This adds a regression line along with a confidence interval.
- Compute the correlation of `attitude` and `points` with `cor.test()`
- Is a linear relationship between attitude and points plausible? 
- How would you characterize the strength of that relationship?

*** =hint
- Remember to add the `+` before the call to `geom_smooth()` on the same line as `qplot()`

*** =pre_exercise_code
```{r}
# pre exercise code here
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

```


*** =sample_code
```{r}
# learning2014 is available

# Access ggplot2 functions
library(ggplot2)

# Exlude students who did not attend any exams (points == 0)
learning2014 <- learning2014[learning2014$points != 0, ]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# A scatter plot of attitude and points
qplot(attitude, points)

# Correlation with a confidence intervals


```

*** =solution
```{r}
# learning2014 is available

# Access ggplot2 functions
library(ggplot2)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# a scatter plot of attitude and points
qplot(attitude, points) + geom_smooth(method = "lm")

# correlation with confidence intervals
cor.test(attitude, points)

```

*** =sct
```{r}

# tests
test_function("geom_smooth", args=c("method"))
test_function("cor.test", args=c("x","y"))

# test error
test_error()


# Final message the student will see upon completing the exercise
success_msg("Nice work!")

```

--- type:NormalExercise lang:r xp:50 skills:1 key:930badee16

## What is a linear model?

Genrally, a [statistical model](https://en.wikipedia.org/wiki/Statistical_model) embodies a set of assumptions concerning the generation of the observed data and similar data from a larger population. A [linear model](https://en.wikipedia.org/wiki/Linear_regression) makes the following assumptions:

- The mean of the response variable is a *linear combination* of the explanatory variable(s) and the parameters.
- The prediction errors of the model are normally distributed.
- The deviation in prediction errors is constant over possible values of the explanatory variable(s).

Regression analysis is based on a linear model - a simple statistical model in which a linear relationship between the mean of the variable of interest (`y`) and some explanatory variable(s) (`x`) is assumed:

`y = a + b*x + errors`, 

where `a` and `b` are unknown parameters to be estimated (a is called the *intercept* and b the *regression coefficient*).

*** =instructions
- Create some toy data, choose the parameters, produce random errors and form the linear model between `x` and `y`
- Draw a scatterplot of `x` and `y` using `plot()`.
- Compute the correlation of `x` and `y`
- The *coefficient of determination* (also called "R squared" - does not refer to the R program, however!) is the correlation squared. Compute it.
- Change the parameter $b$ of the linear model to -1.5 and repeat the above computations.


*** =hint
- The `plot()` function can be used to draw a scatter plot. The first two arguments should be the vectors of x and y values. Use `?plot` if you want more information.
- A value or a vectors of values can be squared by either `^` or `**`.


*** =pre_exercise_code
```{r}
# pre exercise code here

```


*** =sample_code
```{r}
# Here we produce data from a linear model where we choose the parameters

# Create some toy data
x <- c(1,3,7,3,5,8,2,3,10,9,4,5,6,1,2,4,6,6,7,6,3,3,1)

# Choose the parameters and produce random errors
a <- 7
b <- 1.5
e <- rnorm(length(x), sd = 2)

# A linear model for y
y <- a + b*x + e

# Scatter plot of x and y


# Correlation (R)


# Coefficient of determination (R squared)



```

*** =solution
```{r}
# Here we produce data from a linear model where we choose the parameters

# Create some toy data
x <- c(1,3,7,3,5,8,2,3,10,9,4,5,6,1,2,4,6,6,7,6,3,3,1)

# Choose the parameters and produce random errors
a <- 7
b <- -1.5
e <- rnorm(length(x), sd = 2)

# A linear model for y
y <- a + b*x + e

# Scatterplot of x and y
plot(x, y)

# Correlation (R)
cor(x, y)

# Coefficient of determination (R squared)
cor(x, y)**2


```

*** =sct
```{r}

# tests:
test_function("plot", args = c("x","y"), not_called_msg = "Please use the basic plotting function to draw a scatter plot of x and y. ", incorrect_msg = "Did you draw a scatter plot of x and y? Remember to also change the value of b")

test_output_contains("cor(x, y)", incorrect_msg = "Did you compute the correlation of x and y? Remember to also change the value of b.")

test_output_contains("cor(x, y)**2", incorrect_msg = "Did you compute the coefficient of determination?")

# test error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Awsome work! You are making linear progress!")

```


--- type:NormalExercise lang:r xp:100 skills:1 key:261ae48c3e

## Fitting a linear model

Regression analysis is based on a linear model of the form

$$y = a + b*x + errors$$ 

where $x$ denotes the explanatory variable(s), $y$ the dependent variable and $a$ and $b$ are parameters of the model, which need to be estimated using the data. In R, the parameters of a linear model can be estimated using the `lm()` function. This is also called fitting a model.

`lm()` takes as it's first argument a *formula*, which is a symbolic description of the model. For example 

`my_y ~ my_x` 

is a formula stating that `my_y` depends on `my_x`. The second argument of `lm()` is `data`, which defines the data frame where `my_x` and `my_y` are found. `lm()` returns an R object which contains information about the fitted model.

*** =instructions
- Adjust the code: replace both `1` and give the `lm()` function a formula where points is explained by attitude. Adjust the data argument to use the learning2014 data.frame
- Use `summary()` to look at a summary of the fitted model. 

*** =hint
- To use the learning2014 data, replace `NULL` with the `learning2014` object


*** =pre_exercise_code
```{r}
library(ggplot2)
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# a scatter plot of attitude and points
qplot(attitude, points) + geom_smooth(method = "lm")

```


*** =sample_code
```{r}
# learning2014 is available

# Explain students statistics exam points with their attitude toward statistics using a linear model

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(1 ~ 1, data = NULL)

# Look at a summary of my_fit



```

*** =solution
```{r}
# learning2014 is available

# Explain students exam points with their attitude toward statistics with a linear model

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)

# Get a summary() of my_fit
summary(my_fit)



```

*** =sct
```{r}

# tests
test_function("lm", args=c("formula", "data"))
test_object("my_fit")
test_function("summary", args="object")

# test error
test_error()


# Final message the student will see upon completing the exercise
success_msg("Great job, now let's interpret the results!")

```


--- type:MultipleChoiceExercise lang:r xp:100 skills:1 key:802e37215d

## Intepreting a fitted model

Now that we have estimated the parameters of our (simple) model, it is time to interpret the results! First please use any resource to study how to interpret regression coefficients and the p-values related to them. 

Type `summary(my_fit)` on the R console. Which of the following choices are correct?

*** =instructions
- When a students attitude increases by one unit, the expected increase of exam points is 11.6 units. The effect is statistically significant.
- When a students attitude increases by one unit, the expected decrease of exam points is 3.5 units. The effect is statistically significant.
- When a students attitude increases by one unit, the average increase of exam points is 3.5 units. The effect is statistically significant.
- When a students attitude increases by one unit, the expected increase of exam points is 3.5 units. The effect is not statistically significant.

*** =hint
- The first values on the right of `(Intercept)` and `attitude` are the parameter estimates.


*** =pre_exercise_code
```{r}
library(ggplot2)
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# a scatter plot of attitude and points
qplot(attitude, points) + geom_smooth(method = "lm")

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)
```


*** =sct
```{r}

# example tests:
msg1 = "11.6 is the estimate for the intercept (a). This tells you what points would be if attitude were zero."
msg2 = "The coefficient estimate (b) of attitude is positive so they change to the same direction."
msg3 = "Correct!"
msg4 = "The linear relationship between attitude and points is statistically significant according to the computed p-value: It is very unlikely to get this data if the coefficient of attitude actually were zero (=no linear relationship)."

test_mc(correct=3, feedback_msgs=c(msg1, msg2,msg3,msg4))

# test error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Awsome work!")

```

--- type:MultipleChoiceExercise lang:r xp:100 skills:1  key:dc8d2d08dd

## Checking the validity of model assumptions

Let us now return to the <a href = "https://en.wikipedia.org/wiki/Linear_regression#Assumptions" target="_blank">assumptions</a> of our model. We started by looking at the plausibility of a linear relationship, which was the first assumption. We have two assumptions left unchecked:

1. **The variability in prediction errors is constant over possible values of the explanatory variable(s)**
2. **The erros are normally distributed**

The former can be studied graphically by plotting the predictions (fitted values) of our model against the prediction errors (residuals). If there is a visible pattern, that would mean a likely violation to the constant variability assumption.  

The latter assumption can also be studied graphically. A <a href="https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot"<a q-q plot</a> is a powerful way to check if observations follow a theoretical distribution. If this is the case, then the points in the plot should approximately follow a straight increasing line. Deviations from the normality assumption should show a clear non-linear pattern.

When a linear model object such as `my_fit` is given to the `plot()` function as the first argument, `plot()` draws multiple diagnostic plots related to the model. Type `plot(my_fit)` on the R console and choose the correct answer.

*** =instructions
- The scatter plot of fitted values and residuals shows that the values of the residuals depend on the fitted values, violating assumption 1. The q-q plot shows that the distribution of the residuals is approximately normal.
- The scatter plot of fitted values and residuals shows that the values of the residuals do not depend on the fitted values. The q-q plot shows that the residuals and fitted values are independent.
- The scatter plot of fitted values and residuals shows that the values of the residuals do not depend on the fitted values. The q-q plot shows that the distribution of the residuals is approximately normal.
- The scatter plot of fitted values and residuals shows that the values of the residuals do not depend on the fitted values. The q-q plot shows that the distribution of the residuals is not approximately normal, violating assumption 2.

*** =hint
- The first diagnostic plot shows the scatter plot of fitted values and residuals.


*** =pre_exercise_code
```{r}

learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)

```


*** =sct
```{r}
msg1 <- "The scatter plot of fitted values and residuals is the first plot. There seems to be no clear pattern to indicate that the residuals would depend on the fitted values"
msg2 <- "The q-q plot is a graphical tool to check if an empirical distribution fits a theoretical distribution."
msg3 <- "Correct! Both assumptions seem valid in this case"
msg4 <- "The quantile points in the q-q plot follow a straight line quite nicely indicating that the normal distribution assumption is valid."

test_mc(3, feedback_msgs = c(msg1, msg2, msg3, msg4))


# Final message the student will see upon completing the exercise
success_msg("Great work! You are really learning the linear models.")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:d44ed46dc6

## Making predictions with the model

Okey, so we have a linear model which seems to fit our standards. What can we do with it? 

The model quantifies the relationship between the explanatory variable(s) (attitude) and the dependent variable (points). The model can also be used for predicting the dependent variable based on new observations of the explanatory variable(s).

*** =instructions
- Create object `my_fit` and `new_attitudes`
- Adjust the code: Replace `NULL` with the new attitudes to create a new data frame with an attitude column
- Print out the new data frame
- Use the `predict()` function to predict the new students exam points based on their attitude. The argument `newdata` should be a data.frame with the new observations for the explanatory variable(s).

*** =hint
- Type `attitude = new_attitudes` inside the `data.frame()` function.
- Give the `new_data` data frame as the newdata argument for `predict()`


*** =pre_exercise_code
```{r}

learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)
```


*** =sample_code
```{r}
# learning2014 is available

# Create object my_fit explaining students exam points with attitude towards statistics
my_fit <- lm(points ~ attitude, data = learning2014)

# New observations
new_attitudes <- c("Miia" = 3.8, "Matti"= 4.4, "Riikka" = 2.2, "Pekka" = 2.9)
new_data <- data.frame(attitude = NULL)

# Print out the new data


# Predict the new students exam points based on attitude
predict(my_fit, newdata = NULL)


```

*** =solution
```{r}
## learning2014 is available

# Create object my_fit explaining students exam points with attitude towards statistics
my_fit <- lm(points ~ attitude, data = learning2014)

# new observations
new_attitudes <- c("Miia" = 3.8, "Matti"= 4.4, "Riikka" = 2.2, "Pekka" = 2.9)
new_data <- data.frame(attitude = new_attitudes)

# print out the new data
new_data

# predict the students exam points based on attitude
predict(my_fit, newdata = new_data)



```

*** =sct
```{r}

test_object("new_data")
test_function("predict.lm", args=c("object", "newdata"))

# test error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Awsome work! Thank you so much for participating in the course!")

```
