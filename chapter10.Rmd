---
title       : Regression
description : UNDER CONSTRUCTION

--- type:NormalExercise lang:r xp:50 skills:1 key:930badee16

## What is a linear model?

Genrally, a [statistical model](https://en.wikipedia.org/wiki/Statistical_model) embodies a set of assumptions concerning the generation of the observed data and similar data from a larger population. A [linear model](https://en.wikipedia.org/wiki/Linear_regression) makes the following assumptions:

- The mean of the response variable is a *linear combination* of the explanatory variable(s) and the parameters.
- The prediction errors of the model are normally distributed.
- The deviation in prediction errors is constant over possible values of the explanatory variable(s).

Regression analysis is based on a linear model - a simple statistical model in which a linear relationship between the mean of the variable of interest (`y`) and some explanatory variable(s) (`x`) is assumed:

`y = a + b*x + e`, 

where `a` and `b` are unknown parameters to be estimated (a is called the *intercept* and b the *regression coefficient*) and $e$ are the errors.

*** =instructions
- Create some toy data, choose the parameters, produce random errors and form the linear model between `x` and `y`
- Draw a scatterplot of `x` and `y` using `plot()`.
- Compute the correlation of `x` and `y`
- The *coefficient of determination* (also called "R squared" - does not refer to the R program, however!) is the correlation squared. Compute it.
- Change the parameter $b$ of the linear model to -1.5 and repeat the above computations.


*** =hint
- The `plot()` function can be used to draw a scatter plot. The first two arguments should be the vectors of x and y values. Use `?plot` if you want more information.
- A value or a vectors of values can be squared by either `^` or `**`.


*** =pre_exercise_code
```{r}
# pre exercise code here

```


*** =sample_code
```{r}
# Here we produce data from a linear model where we choose the parameters

# Create some toy data
x <- c(1,3,7,3,5,8,2,3,10,9,4,5,6,1,2,4,6,6,7,6,3,3,1)

# Choose the parameters and produce random errors
a <- 7
b <- 1.5
e <- rnorm(length(x), sd = 2)

# A linear model for y
y <- a + b*x + e

# Scatter plot of x and y


# Correlation (R)


# Coefficient of determination (R squared)



```

*** =solution
```{r}
# Here we produce data from a linear model where we choose the parameters

# Create some toy data
x <- c(1,3,7,3,5,8,2,3,10,9,4,5,6,1,2,4,6,6,7,6,3,3,1)

# Choose the parameters and produce random errors
a <- 7
b <- -1.5
e <- rnorm(length(x), sd = 2)

# A linear model for y
y <- a + b*x + e

# Scatterplot of x and y
plot(x, y)

# Correlation (R)
cor(x, y)

# Coefficient of determination (R squared)
cor(x, y)**2


```

*** =sct
```{r}

# tests:
test_function("plot", args = c("x","y"), not_called_msg = "Please use the basic plotting function to draw a scatter plot of x and y. ", incorrect_msg = "Did you draw a scatter plot of x and y? Remember to also change the value of b")

test_output_contains("cor(x, y)", incorrect_msg = "Did you compute the correlation of x and y? Remember to also change the value of b.")

test_output_contains("cor(x, y)**2", incorrect_msg = "Did you compute the coefficient of determination?")

# test error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Awsome work! You are making linear progress!")

```


--- type:NormalExercise lang:r xp:150 skills:1 key:e2d130649d

## Exploring the relationship of two variables

It is always a good idea to start with the simplest possible explorations before more complicated statistical analysis. A scatter plot is always a good starting point when analyzing the relationship between variables. Sample correlations are another useful tool.

In the ggplot2 library, scatter plots can be drawn with the general `qplot()` function. In base R `cor.test()` can be used to compute a correlation with a confidence interval.

*** =instructions
- Access the ggplot2 library, modify the learning2014 data and draw a scatter plot of `attitude` and `points`.
- Adjust the scatter plot: Add code `+ geom_smooth()` after `qplot()`. Write the code to the same line and do not forget the plus sign. Execute the row.
- Give the function `geom_smooth()` the argument `method = "lm"` and execute the line again. This adds a regression line along with a confidence interval.
- Compute the correlation of `attitude` and `points` with `cor.test()`
- Is a linear relationship between attitude and points plausible? (hint: the scatter plot) How would you characterize the strength of that relationship? (hint: the correlation)

*** =hint
- Remember to add the `+` before the call to `geom_smooth()` on the same line as `qplot()`

*** =pre_exercise_code
```{r}
# pre exercise code here
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

```


*** =sample_code
```{r}
# learning2014 is available

# Access ggplot2 functions
library(ggplot2)

# Exlude students who did not attend any exams (points == 0)
learning2014 <- learning2014[learning2014$points != 0, ]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# A scatter plot of attitude and points
qplot(attitude, points)

# Correlation with a confidence intervals


```

*** =solution
```{r}
# learning2014 is available

# Access ggplot2 functions
library(ggplot2)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# a scatter plot of attitude and points
qplot(attitude, points) + geom_smooth(method = "lm")

# correlation with confidence intervals
cor.test(attitude, points)

```

*** =sct
```{r}

# tests
test_function("geom_smooth", args=c("method"))
test_function("cor.test", args=c("x","y"))

# test error
test_error()


# Final message the student will see upon completing the exercise
success_msg("Nice work!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:261ae48c3e

## Fitting a linear model

Regression analysis is based on a linear model of the form

$$y = a + b*x + e$$ 

where $x$ denotes the explanatory variable(s), $y$ the dependent variable and $a$ and $b$ are parameters of the model, which need to be estimated using the data. In R, the parameters of a linear model can be estimated using the `lm()` function. This is also called fitting a model.

`lm()` takes as it's first argument a *formula*, which is a symbolic description of the model. For example 

`my_y ~ my_x` 

is a formula stating that `my_y` depends on `my_x`. The second argument of `lm()` is `data`, which defines the data frame where `my_x` and `my_y` are found. `lm()` returns an R object which contains information about the fitted model.

*** =instructions
- Adjust the code: replace both `1` and give the `lm()` function a formula where points is explained by attitude. Adjust the data argument to use the learning2014 data.frame
- Use `summary()` to look at a summary of the fitted model. 

*** =hint
- To use the learning2014 data, replace `NULL` with the `learning2014` object


*** =pre_exercise_code
```{r}
library(ggplot2)
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# a scatter plot of attitude and points
qplot(attitude, points) + geom_smooth(method = "lm")

```


*** =sample_code
```{r}
# learning2014 is available

# Explain students statistics exam points with their attitude toward statistics using a linear model

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(1 ~ 1, data = NULL)

# Look at a summary of my_fit



```

*** =solution
```{r}
# learning2014 is available

# Explain students exam points with their attitude toward statistics with a linear model

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)

# Get a summary() of my_fit
summary(my_fit)



```

*** =sct
```{r}

# tests
test_function("lm", args=c("formula", "data"))
test_object("my_fit")
test_function("summary", args="object")

# test error
test_error()


# Final message the student will see upon completing the exercise
success_msg("Great job, now let's interpret the results!")

```


--- type:MultipleChoiceExercise lang:r xp:100 skills:1 key:802e37215d

## Intepreting a fitted model

Now that we have estimated the parameters of our (simple) model, it is time to interpret the results! First please use any resource to study how to interpret regression coefficients and the p-values related to them. 

Type `summary(my_fit)` on the R console. Which of the following choices are correct?

*** =instructions
- When a students attitude increases by one unit, the expected increase of exam points is 11.6 units. The effect is statistically significant.
- When a students attitude increases by one unit, the expected decrease of exam points is 3.5 units. The effect is statistically significant.
- When a students attitude increases by one unit, the average increase of exam points is 3.5 units. The effect is statistically significant.
- When a students attitude increases by one unit, the expected increase of exam points is 3.5 units. The effect is not statistically significant.

*** =hint
- The first values on the right of `(Intercept)` and `attitude` are the parameter estimates.


*** =pre_exercise_code
```{r}
library(ggplot2)
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create objects attitude and points
attitude <- learning2014$attitude
points <- learning2014$points

# a scatter plot of attitude and points
qplot(attitude, points) + geom_smooth(method = "lm")

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)
```


*** =sct
```{r}

# example tests:
msg1 = "11.6 is the estimate for the intercept (a). This tells you what points would be if attitude were zero."
msg2 = "The coefficient estimate (b) of attitude is positive so they change to the same direction."
msg3 = "Correct!"
msg4 = "The linear relationship between attitude and points is statistically significant according to the computed p-value: It is very unlikely to get this data if the coefficient of attitude actually were zero (=no linear relationship)."

test_mc(correct=3, feedback_msgs=c(msg1, msg2,msg3,msg4))

# test error
test_error()

# Final message the student will see upon completing the exercise
success_msg("Awsome work!")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:6c1fbe3364

## Checking the validity of model assumptions (1)

Let us now return to the assumptions of our model. We started by looking at the plausibility of a linear relationship, which was the first assumption. We have two assumptions left unchecked:

1. **The variability in prediction errors is constant over possible values of the explanatory variable(s)**
2. The erros are normally distributed

First let's focus on the former, which can be studied graphicaly by plotting the predictions of our model against the prediction errors (residuals). If there is a visible pattern, that would mean a likely violation to the constant variability assumption. You can read more on <a href = "https://en.wikipedia.org/wiki/Linear_regression#Assumptions" target="_blank">wikipedia</a>.

The `my_fit` object you have created is actually a *list*, which is a similar object to a data frame in R. A list's elements can be accessed with the `$` sign. `my_fit` contains - among other useful things - the linear predictions and prediction errors (residuals) of your model. They are named `fitted.values` and `residuals`.


*** =instructions
- Access the ggplot2 library and create `my_fit`
- Create object `predictions`
- Create object `residuals` by accessing residuals in `my_fit`
- Use `qplot()` to draw a scatter plot of predictions and the residuals, with residuals on the y axis.
- Do you see any clear pattern?

*** =hint
- Use `numeric_object^2` or `numeric_object**2` to raise all elements of `numeric_object` to the power of two.


*** =pre_exercise_code
```{r}
library(ggplot2)

learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)

```


*** =sample_code
```{r}
# learning2014 is available

library(ggplot2)

# Create object my_fit explaining students exam points with their attitude towards statistics
my_fit <- lm(points ~ attitude, data = learning2014)

# Create object predictions by accessing fitted.values in my_fit
predictions <- my_fit$fitted.values

# Create object residuals by accessing residuals in my_fit


# Draw a scatter plot of the predictions and residuals


```

*** =solution
```{r}
# learning2014 is available

library(ggplot2)

# Create object my_fit explaining students exam points with their attitude towards statistics
my_fit <- lm(points ~ attitude, data = learning2014)

# Create object predictions by accessing fitted.values in my_fit
predictions <- my_fit$fitted.values

# Create object residuals by accessing residuals in my_fit
residuals <- my_fit$residuals

# Draw a scatter plot of the predictions and residuals
qplot(predictions, residuals)


```

*** =sct
```{r}

test_object("residuals", incorrect_msg = "Please create the object `residuals` by accessing the residuals in `my_fit`")
test_function("qplot", args=c("x","y"))

# test error
test_error()


# Final message the student will see upon completing the exercise
success_msg("Great work! You are really learning the linear models.")

```

--- type:NormalExercise lang:r xp:100 skills:1 key:fcee2bd6a3

## Checking the validity of model assumptions (2)

We have one assumption left unchecked: The predictions errors (residuals) should be normally distributed. A good place to start is by drawing a histogram of the errors to see the distibution. 

There is also a more powerful way to check if observations follow a theoretical distribution: <a href="https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot"<a q-q plot</a>.

A q-q plot plots the theoretical quantiles against observed quantiles and if these two agree, then the points of the plot should approximately follow a straight increasing line. There will always be slight deviations from the line, but deviations from the normality assumption should show a clear non-linear pattern.

In base R, a q-q plot can be drawn with the `qqnorm()` and `qqline()` functions. The first argument of both is `y`, a numeric vector of the values whose distribution we are interested in.

*** =instructions
- Create object `rsiduals` by accessing the residuals in `my_fit`
- Draw a histogram to visualize the distribution of the residuals. Is the distribution approximately normal?
- Draw a q-q plot of the errors using the `qqnorm()` function and add a line to the plot with `qqline()`
- Do the points follow the line reasonably well? Is there a clear non-linear pattern?

*** =hint
- Remember that you can use `$` to access the values of a list such as `my_fit`


*** =pre_exercise_code
```{r}
library(ggplot2)

learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/learning2014.txt", sep = "\t", header = TRUE)

# Exlude students who did not attend exams (points = 0)
learning2014 <- learning2014[learning2014$points != 0,]

# Create object my_fit explaining points with attitude in the learning2014 data
my_fit <- lm(points ~ attitude, data = learning2014)
```


*** =sample_code
```{r}
# learning2014 is available

# Create object my_fit explaining students exam points with attitude towards statistics
my_fit <- lm(points ~ attitude, data = learning2014)

# create object residuals
residuals <- NULL

# Draw a histogram of the residuals


# Draw a qqplot of the residuals using qqnorm() and qqline()
qqnorm(residuals); qqline(residuals)



```

*** =solution
```{r}
# learning2014 is available

# Create object my_fit explaining students exam points with attitude towards statistics
my_fit <- lm(points ~ attitude, data = learning2014)

# Create object residuals
residuals <- my_fit$residuals

# Draw a histogram of the residuals
hist(residuals)

# Draw a qqplot of the residuals using qqnorm() and qqline()
qqnorm(residuals); qqline(residuals)




```

*** =sct
```{r}

# tests
test_object("residuals")
test_function("hist", args="x")

# test error
test_error()


# Final message the student will see upon completing the exercise
success_msg("Awsome work! Now you know how to fit and validate linear models!")

```
